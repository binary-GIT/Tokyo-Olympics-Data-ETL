# Tokyo-Olympics-Data-ETL

# Overview
This project focuses on building a comprehensive data engineering pipeline for the Tokyo Olympic Games, leveraging Azure services such as Data Lake Gen2, Data Factory, Databricks, and Synapse Analytics. The pipeline aims to handle data integration, transformation, and analysis to support valuable insights for the Olympic events.

#Technologies Used
Azure Data Lake Gen2: Storage for raw and processed data.
Azure Data Factory: Orchestration and automation of data workflows.
Azure Databricks: Advanced analytics and data transformation.
Azure Synapse Analytics: Data warehousing and analytics.

# Project Structure
Data Ingestion: Raw data from various sources is ingested into Data Lake Gen2.
ETL Pipeline: Data is processed and transformed using Azure Data Factory, leading to curated datasets.
Advanced Analytics: Complex analytics and transformations are performed in Azure Databricks.
Data Warehousing: Synapse Analytics is utilized for scalable data warehousing and efficient querying.

# Setup Instructions
Azure Account: Ensure you have an active Azure account.
Azure Resources: Create necessary Azure resources - Data Lake Gen2, Data Factory, Databricks, and Synapse Analytics.
Configuration: Update configuration files with your Azure credentials and project-specific details.
Run Pipelines: Execute Data Factory pipelines for ETL, monitor Databricks jobs, and utilize Synapse Analytics for analytics.
Usage

Follow the documentation provided in the 'docs' directory for detailed instructions on setting up, running, and maintaining the project.
For any issues or inquiries, refer to the 'issues' section in this repository.
